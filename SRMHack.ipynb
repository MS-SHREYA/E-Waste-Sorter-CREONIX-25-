{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "sC3IVSqolsZp",
        "outputId": "ddeacba4-79f6-41d4-fc9c-cdef2527dab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ AI Model loaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://f6cc9ac71127ca243f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f6cc9ac71127ca243f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# --- 1. INSTALL LIBRARIES ---\n",
        "!pip install -q gradio ultralytics opencv-python numpy\n",
        "\n",
        "# --- 2. IMPORT LIBRARIES ---\n",
        "import gradio as gr\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from collections import defaultdict\n",
        "\n",
        "# --- 3. LOAD YOUR AI MODEL ---\n",
        "# Make sure your Google Drive is mounted and the path is correct\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "MODEL_PATH = '/content/best (1).pt'\n",
        "\n",
        "try:\n",
        "    model = YOLO(MODEL_PATH)\n",
        "    print(\"✅ AI Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ CRITICAL ERROR: Could not load the model. Please check the path: {e}\")\n",
        "    raise SystemExit(\"Model loading failed.\")\n",
        "\n",
        "# --- 4. COMPONENT DATABASE WITH ALL DETAILS ---\n",
        "COMPONENT_DATABASE = {\n",
        "    'ic': {'tier': 'High-Value', 'score': 10, 'description': \"are prime candidates for harvesting due to their high resale value and functionality.\", 'hazardous': False},\n",
        "    'coil': {'tier': 'Medium-Value', 'score': 3, 'description': \"are valuable for their copper content and are often reused in power circuits.\", 'hazardous': False},\n",
        "    'mosfet': {'tier': 'Medium-Value', 'score': 3, 'description': \"are key components in power regulation and are frequently harvested for repair.\", 'hazardous': True},\n",
        "    'transistor': {'tier': 'Low-Value', 'score': 0, 'description': \"\", 'hazardous': True},\n",
        "    'default': {'tier': 'Low-Value', 'score': 0, 'description': \"\", 'hazardous': False}\n",
        "}\n",
        "\n",
        "# --- 5. THE MAIN ANALYSIS FUNCTION ---\n",
        "def analyze_pcb_with_gradio(input_image):\n",
        "    img = cv2.cvtColor(input_image, cv2.COLOR_RGB2BGR)\n",
        "    results = model(img)\n",
        "\n",
        "    # --- Analysis Logic ---\n",
        "    component_counts = defaultdict(int)\n",
        "    reusability_score = 0\n",
        "    total_components = 0\n",
        "    detailed_factors = defaultdict(list)\n",
        "    is_hazardous = False\n",
        "\n",
        "    for box in results[0].boxes:\n",
        "        total_components += 1\n",
        "        class_name = model.names[int(box.cls[0])]\n",
        "        confidence = float(box.conf[0])\n",
        "        component_counts[class_name] += 1\n",
        "\n",
        "        data = COMPONENT_DATABASE.get(class_name, COMPONENT_DATABASE['default'])\n",
        "        reusability_score += data['score']\n",
        "\n",
        "        if data['score'] > 0:\n",
        "            detailed_factors[class_name.capitalize()].append(data['description'])\n",
        "\n",
        "        if data['hazardous']:\n",
        "            is_hazardous = True\n",
        "\n",
        "        # Drawing bounding boxes\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "        label = f\"{class_name} {confidence:.2f}\"\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    if total_components > 50:\n",
        "        reusability_score += 15\n",
        "        detailed_factors[\"Board Complexity\"].append(\"This board has a high component density, often indicating a more valuable board.\")\n",
        "\n",
        "    # --- 6. SEGREGATION RECOMMENDATION LOGIC ---\n",
        "    if is_hazardous:\n",
        "        recommendation = \"☣️ HAZARDOUS: Segregate for special disposal.\"\n",
        "    elif reusability_score >= 20:\n",
        "        recommendation = \"♻️ REUSABLE: Segregate for component harvesting.\"\n",
        "    else:\n",
        "        recommendation = \"⚙️ GENERAL RECYCLING: Route to standard shredding process.\"\n",
        "\n",
        "    # --- 7. FORMAT THE DETAILED REPORT ---\n",
        "    report = \"--- FULL BOARD ANALYSIS REPORT ---\\n\\n\"\n",
        "    report += \"[ 1. COMPONENT SUMMARY ]\\n\"\n",
        "    for component, count in component_counts.items():\n",
        "        report += f\"- {component.capitalize()}: {count} units\\n\"\n",
        "\n",
        "    report += \"\\n[ 2. DETAILED REUSABILITY ANALYSIS ]\\n\"\n",
        "    if reusability_score >= 40: verdict = \"Prime Candidate for Component Harvesting.\"\n",
        "    elif reusability_score >= 10: verdict = \"Good Potential for Reuse.\"\n",
        "    else: verdict = \"Low Potential for Reuse.\"\n",
        "    report += f\"Reusability Score: {reusability_score} / 100\\n\"\n",
        "    report += f\"Verdict: {verdict}\\n\"\n",
        "\n",
        "    if detailed_factors:\n",
        "        report += \"\\nFactors Considered in This Decision:\\n\"\n",
        "        for component_name, descriptions in detailed_factors.items():\n",
        "            unique_description = descriptions[0]\n",
        "            count = component_counts.get(component_name.lower(), len(descriptions))\n",
        "            if \"Board Complexity\" in component_name:\n",
        "                 report += f\"  {component_name}: {unique_description}\\n\"\n",
        "            else:\n",
        "                 report += f\"  {count} x {component_name}: Detected. These {unique_description}\\n\"\n",
        "\n",
        "    annotated_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return recommendation, report, annotated_image\n",
        "\n",
        "# --- 8. CREATE AND LAUNCH THE GRADIO INTERFACE ---\n",
        "iface = gr.Interface(\n",
        "    fn=analyze_pcb_with_gradio,\n",
        "    inputs=gr.Image(type=\"numpy\", label=\"Upload PCB Image\"),\n",
        "    outputs=[\n",
        "        # ✨ MODIFIED: Recommendation box is now a single line again\n",
        "        gr.Textbox(label=\"✅ Final Segregation Recommendation\"),\n",
        "        # ✨ MODIFIED: Detailed report box is large\n",
        "        gr.Textbox(label=\"Detailed Analysis Report\", lines=20),\n",
        "        gr.Image(type=\"numpy\", label=\"Detection Result\", height=600)\n",
        "    ],\n",
        "    title=\"E-Waste PCB Analyzer & Sorter\",\n",
        "    description=\"Upload a circuit board image to get a detailed analysis and a clear segregation recommendation.\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "# Launch the app with a public link\n",
        "iface.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjUUZgSdwM6w",
        "outputId": "d4b2dd6e-ec14-41b0-fbab-94b503d8bdfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.9-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.8.3)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Collecting pi-heif<2 (from roboflow)\n",
            "  Downloading pi_heif-1.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.60.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.3)\n",
            "Downloading roboflow-1.2.9-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.0 pillow-avif-plugin-1.5.2 roboflow-1.2.9\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in PCB-components-1 to yolov8:: 100%|██████████| 53983/53983 [00:01<00:00, 50272.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to PCB-components-1 in yolov8:: 100%|██████████| 134/134 [00:00<00:00, 935.33it/s] \n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"6iTMOIcJZY6uftvqd3iI\")\n",
        "project = rf.workspace(\"srmhack\").project(\"pcb-components-r8l8r-pm1ig\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC-bX9g-kF42",
        "outputId": "770d7c55-056a-4fb1-d326-32db97bb7a35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f427f25"
      },
      "source": [
        "# Task\n",
        "Set up a web application using a Python framework (Flask or Django) to host a YOLO model for object detection. The application should have a web interface for image uploads, process the images using the YOLO model, and display the detection results (bounding boxes and component summary) to the user. Finally, provide instructions on how to deploy and access the application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11f96da5"
      },
      "source": [
        "## Set up a web framework\n",
        "\n",
        "### Subtask:\n",
        "Choose a Python web framework like Flask or Django to build your web application.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "142798e7"
      },
      "source": [
        "**Reasoning**:\n",
        "Flask is a good choice for this project as it is a microframework and the application is relatively simple, focusing on image upload and model inference. The first step is to install Flask using pip.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed55d422"
      },
      "source": [
        "## Create a web interface\n",
        "\n",
        "### Subtask:\n",
        "Design a simple HTML interface with a file upload form for users to submit images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c1fcfe1"
      },
      "source": [
        "**Reasoning**:\n",
        "Create the HTML file with a file upload form as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4646835c"
      },
      "source": [
        "## Implement backend logic\n",
        "\n",
        "### Subtask:\n",
        "Write Python code to receive the uploaded image, save it temporarily, and pass it to your trained YOLO model for inference.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4d385ea"
      },
      "source": [
        "**Reasoning**:\n",
        "Write the Python code for the Flask application to handle image uploads, perform inference using the YOLO model, and prepare the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnLTwH_OywIT"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36f7c80e"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed because the `ultralytics` library was not found. I need to install it before importing and using the YOLO model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRJWbNM5-TDJ"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc251b5b"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that `ultralytics` is installed, I can re-run the code to define the Flask application, load the YOLO model, and handle the image upload and inference.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40f96784"
      },
      "source": [
        "## Implement backend logic\n",
        "\n",
        "### Subtask:\n",
        "Retry implementing the backend logic to receive the uploaded image, save it temporarily, and pass it to your trained YOLO model for inference.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "727597b2"
      },
      "source": [
        "**Reasoning**:\n",
        "Update the model path in the code to the correct location and attempt to load the model again.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cad45384"
      },
      "source": [
        "## Display results\n",
        "\n",
        "### Subtask:\n",
        "Render the results back to the user, potentially by drawing bounding boxes on the uploaded image and displaying the component summary.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44da6b6a"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempts to load the model from Google Drive failed due to mounting issues. I will modify the Flask application code to render an HTML template that displays the detected image and component summary after processing, create the necessary HTML template file, add a route to serve the processed image, and ensure the Flask app is set up to run, incorporating necessary imports for rendering templates and serving static files. I will also adjust the model loading to use the path where the model was successfully downloaded in a previous step of the notebook, which is `/content/runs/detect/train/weights/best.pt`, to avoid the Google Drive mounting dependency.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a306935"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed because it attempted to use the `%%writefile` magic command within a Python script block. I need to separate the creation of the `results.html` file using `%%writefile` into its own cell and then define the Flask application code in a separate cell. I will also create the `templates` directory before attempting to write the HTML file into it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d423c89a"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `templates` directory is created, I can write the `results.html` content into the file using the `%%writefile` magic command in a separate cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9dbde32"
      },
      "source": [
        "**Reasoning**:\n",
        "With the `results.html` template successfully created, I can now define the Flask application code that utilizes this template and includes the routes for serving the processed images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afc3c3e0"
      },
      "source": [
        "## Deploy the application\n",
        "\n",
        "### Subtask:\n",
        "Choose a hosting platform (e.g., Heroku, Google App Engine, AWS) to deploy your web application so it's accessible as a website.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a511046"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps have set up the Flask application and the necessary templates. The current subtask is to select a hosting platform and prepare the application for deployment, which involves creating a `requirements.txt` file listing all necessary Python packages. This file is crucial for the hosting platform to set up the correct environment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4L_OhiGIABtp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cce72dcf"
      },
      "outputs": [],
      "source": [
        "%%writefile requirements.txt\n",
        "Flask\n",
        "ultralytics\n",
        "opencv-python\n",
        "numpy\n",
        "Pillow # Added Pillow as it's often a dependency for image processing and ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ba4e12c"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Flask was chosen as the web framework for the application.\n",
        "*   An `index.html` file was created with a form for image uploads.\n",
        "*   A `results.html` template was created to display the processed image and component summary using Jinja2 templating.\n",
        "*   The Flask application code was defined with routes for the home page (`/`), file upload and processing (`/upload`), and serving processed images (`/processed_images/<filename>`).\n",
        "*   The `/upload` route includes logic to save the uploaded image, perform inference using a YOLO model, draw bounding boxes and labels on the image, count components, save the processed image, and render the `results.html` template.\n",
        "*   A `requirements.txt` file was created listing the necessary Python dependencies (`Flask`, `ultralytics`, `opencv-python`, `numpy`, `Pillow`) for deployment.\n",
        "*   The process encountered and reported errors related to loading the YOLO model, initially due to `ultralytics` not being installed, then a `FileNotFoundError` for the model path, and subsequently a `ValueError` during Google Drive mounting attempts. Despite these errors preventing full application functionality, the code for handling uploads, inference processing, and rendering results was implemented.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The primary next step is to resolve the YOLO model loading issue by ensuring the model file is accessible at the specified `model_path` within the environment where the Flask application is run or deployed. This might involve adjusting the path, ensuring the file exists, or correctly configuring access to cloud storage if the model is stored there.\n",
        "*   To make the application fully functional and accessible via a web browser, the Flask application needs to be executed using `app.run()` (for local testing) or deployed to a hosting platform (like Google Cloud Platform, Heroku, etc.) using a production-ready server (like Gunicorn or uWSGI). The deployment process will also require configuring the hosting environment to serve the application and handle file uploads and static assets (like the processed images).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}